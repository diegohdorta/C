---
layout: post
title: "OpenCL: CPU vs GPU on iMX8"
author: "Diego Dorta"
categories: tutorial
tags: [ cpu, gpu, benchmark, opencl, imx8 ]
---

Nowadays, there is a great demand for technological devices in terms of _power
processing_ and _speed_. To keep update and follow the advances several companies
found ways of getting improvements on its devices. A way that _Apple Inc._ found
was to create a _Open Computing Language_ (_OpenCL_). On June 16 of 2008, _Apple_
offered a proposal to [_Khronos Group_](https://www.khronos.org/) for working together on _OpenCL_. After
lots of cups of coffee and a few months later on December 8 of 2008, the
_OpenCL 1.0_ was released to the community.

The following post can help getting more information regarding its workings and
usage, toolchain, compilation, and examples for running on `iMX8` boards:

* [`Using OpenCL on iMX8`](https://diegodorta.com.br/gpu/OpenCL-Overview.html)

This post intends to provide a [`Benchmarking`](https://en.wikipedia.org/wiki/Benchmarking)
of the `iMX8 QXP MEK` power and speed processing while calculating mathematical additions.
The both next written codes does the same calculation, but one uses the `GPU` and the
other uses normal `CPU`.

The following examples can be found in the
[`GitHub`](https://github.com/diegohdorta/feynman/tree/master/OpenCL).

## Vectors Additions using CPU

This example was written in _C_ and it does the _addition_ of two vectors. It also
calculates the time using the `time.h` library:

<script src="https://gist.github.com/diegohdorta/7d3e96d93802f125e5dc500400829670.js"></script>

All the instructions for compiling and running this example on `iMX8` can be found
in the previous post. The execution of the above code gets the following result:

<center><img src="{{site.url}}{{site.baseurl}}/assets/cpu_bench.gif"/></center>

We can see here that `CPU` took about `0.033` seconds to calculate the addition of
these two vectors. Next steps is to run `GPU` and compare the results.

## Vectors Additions using GPU

To create the exactly same example for `GPU` is a little more complicate. The main
header is `OpenCL` (_cl.h_) and can be found in _/usr/lib/CL_ in the _root file system_.
It requires _libGAL.so_ which does call to `GPU Vivante`, and _libOpenCL.so_ which
corresponds to interfaces and implementations of `OpenCL`. Both can be found in
_/usr/lib_. To calculate the time it was created a _queue_ with enable _profiling_.

Follow the _kernel_ code:

<script src="https://gist.github.com/diegohdorta/bac582e82b0aff07e5100f0d5ab61d8c.js"></script>

Follow the _C_ code:

<script src="https://gist.github.com/diegohdorta/098e3e3a117d4aa903f1e110151bfd69.js"></script>

Again, all the instructions for compiling and running this example can be found
in the previous post. The execution of the above example gets the following result:

<center><img src="{{site.url}}{{site.baseurl}}/assets/gpu_bench.gif"/></center>

We can see here that `GPU` took about `0.003` seconds to calculate the addition of
these two vectors, approximately `10` times faster than `CPU`, or `11` to be exactly.
The next plot shows the difference of these results in a graphical way:

<center><img src="{{site.url}}{{site.baseurl}}/assets/cpuvsgpu.png"/></center>

Although this example is simple, we can see that there is a difference between this
to _units_. It is highly recommended to use `GPU` when the subject is related to
_Games_, _3D Visualization_, _Image Processing_, and **trending** ones _Big Data_ and
_Deep Machine Learning_.

# Machine Learning using GPU

`ML` has been around a long time, but the powerful and efficient GPU computing has raised
it to a new level. _Deep Learning_ is the use of _neural networks_ very sophisticated to
create systems that can be perform detection from enormous, massive amounts of _unlabeled_
training data. `GPU` is able to process tons of training data and train _neural networks_
in areas like:

* _Image and video analysis_;
* _Speech recognition and natural processing_;
* _Self-driving cars_;
* _Computer vision and much more_.

Be aware that `GPU` are not replacements for `CPU` architecture. Rather, they are
powerful accelerators for existing infrastructure. _GPU-accelerated_ computing
[_offloads_](https://en.wikipedia.org/wiki/Computation_offloading)
compute-intensive portions of the applications to the `GPU`, while the remainder of
the code stills runs on the `CPU`. For a normal user and its perspective, applications
are just running faster. While general-purpose computing is still in the domain of the
`CPU`. `GPU` is the backbone of nearly all intensive computational applications.



